{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from __future__ import annotations\n",
    "\n",
    "from typing import Dict, List\n",
    "import matplotlib.pyplot as plt\n",
    "from mme_shuffled_signals import MM_shuffled\n",
    "from utils import*\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import trange\n",
    "from itertools import permutations\n",
    "import pandas as pd\n",
    "from alphacsc import BatchCDL,learn_d_z\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.182774513033785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 47/100 [00:16<00:18,  2.90it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 203\u001b[39m\n\u001b[32m    199\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mAccuracies\u001b[39m\u001b[33m\"\u001b[39m: Accuracies, \u001b[33m\"\u001b[39m\u001b[33mMSEs_sum\u001b[39m\u001b[33m\"\u001b[39m: MSEs_sum, \u001b[33m\"\u001b[39m\u001b[33msnr_grid\u001b[39m\u001b[33m\"\u001b[39m: snr_grid}\n\u001b[32m    202\u001b[39m \u001b[38;5;66;03m# example call:\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m results = \u001b[43mrun_mc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk1\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk2\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m121\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflips\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m40\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mspike\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 171\u001b[39m, in \u001b[36mrun_mc\u001b[39m\u001b[34m(k1, k2, N, flips, n_trials, mode, seed, mindist, T1_2, Fs, snr_grid)\u001b[39m\n\u001b[32m    166\u001b[39m Z_hat_sum = reconstruction_params(\n\u001b[32m    167\u001b[39m     Xk=Xk_sum, t_est=t_est_sum, N=N, alpha=alpha, mode=mode\n\u001b[32m    168\u001b[39m )\n\u001b[32m    170\u001b[39m \u001b[38;5;66;03m# robust MM-based estimation for 2-channel unshuffling\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m171\u001b[39m b1, b2, _, _, q_hat, losses = \u001b[43mMM_shuffled\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m    \u001b[49m\u001b[43my1_obs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my2_obs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mZ_hat_sum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mouteriter\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbdp\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.5\u001b[39;49m\n\u001b[32m    173\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[38;5;66;03m# assignment-invariant normalized MSE\u001b[39;00m\n\u001b[32m    176\u001b[39m mse11 = \u001b[32m0.5\u001b[39m * (\n\u001b[32m    177\u001b[39m     np.mean((clean1 - Z_hat_sum @ b1) ** \u001b[32m2\u001b[39m) / np.mean(clean1 ** \u001b[32m2\u001b[39m)\n\u001b[32m    178\u001b[39m     + np.mean((clean2 - Z_hat_sum @ b2) ** \u001b[32m2\u001b[39m) / np.mean(clean2 ** \u001b[32m2\u001b[39m)\n\u001b[32m    179\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/Cross-Channel-Unlabeled-Sensing/mme_shuffled_signals.py:128\u001b[39m, in \u001b[36mMM_shuffled\u001b[39m\u001b[34m(y1_in, y2_in, X_in, bdp, outeriter, project)\u001b[39m\n\u001b[32m    124\u001b[39m betas2: List[np.ndarray] = []\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(outeriter):\n\u001b[32m    127\u001b[39m     \u001b[38;5;66;03m# robust starts (S) + MM\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     bs1, ss1 = \u001b[43mfastsreg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY1_est\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbdp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    129\u001b[39m     bs2, ss2 = fastsreg(X, Y2_est, bdp, \u001b[32m10\u001b[39m)\n\u001b[32m    130\u001b[39m     bm1, _ = mmregres(X, Y1_est, bs1, ss1, \u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/Cross-Channel-Unlabeled-Sensing/mme_shuffled_signals.py:552\u001b[39m, in \u001b[36mfastsreg\u001b[39m\u001b[34m(x, y, bdp, N)\u001b[39m\n\u001b[32m    549\u001b[39m superbestbeta = bestbetas[\u001b[32m0\u001b[39m, :].copy()\n\u001b[32m    551\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(bestr - \u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m, -\u001b[32m1\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m552\u001b[39m     _, betarw, scalerw = \u001b[43mress\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbestbetas\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbestscales\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    553\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m scalerw < superbestscale:\n\u001b[32m    554\u001b[39m         superbestscale = scalerw\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/Cross-Channel-Unlabeled-Sensing/mme_shuffled_signals.py:796\u001b[39m, in \u001b[36mress\u001b[39m\u001b[34m(x, y, initialbeta, k, conv, kp, c, initialscale)\u001b[39m\n\u001b[32m    794\u001b[39m xw = x * sw[:, \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[32m    795\u001b[39m yw = y * sw\n\u001b[32m--> \u001b[39m\u001b[32m796\u001b[39m beta1 = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinalg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpinv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxw\u001b[49m\u001b[43m.\u001b[49m\u001b[43mT\u001b[49m\u001b[43m \u001b[49m\u001b[43m@\u001b[49m\u001b[43m \u001b[49m\u001b[43mxw\u001b[49m\u001b[43m)\u001b[49m @ (xw.T @ yw)\n\u001b[32m    797\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m np.isnan(beta1).any():\n\u001b[32m    798\u001b[39m     beta1 = initialbeta\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/Cross-Channel-Unlabeled-Sensing/.venv/lib/python3.13/site-packages/numpy/linalg/_linalg.py:2174\u001b[39m, in \u001b[36m_pinv_dispatcher\u001b[39m\u001b[34m(a, rcond, hermitian, rtol)\u001b[39m\n\u001b[32m   2169\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m count_nonzero(S > tol, axis=-\u001b[32m1\u001b[39m)\n\u001b[32m   2172\u001b[39m \u001b[38;5;66;03m# Generalized inverse\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2174\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_pinv_dispatcher\u001b[39m(a, rcond=\u001b[38;5;28;01mNone\u001b[39;00m, hermitian=\u001b[38;5;28;01mNone\u001b[39;00m, *, rtol=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m   2175\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (a,)\n\u001b[32m   2178\u001b[39m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_pinv_dispatcher)\n\u001b[32m   2179\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpinv\u001b[39m(a, rcond=\u001b[38;5;28;01mNone\u001b[39;00m, hermitian=\u001b[38;5;28;01mFalse\u001b[39;00m, *, rtol=_NoValue):\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "def run_mc(\n",
    "    k1: int = 2,\n",
    "    k2: int = 2,\n",
    "    N: int = 121,\n",
    "    flips: int = 50,\n",
    "    n_trials: int = 100,\n",
    "    mode: str = \"spike\",\n",
    "    seed: int = 42,\n",
    "    mindist: float = 1 / 50 + 0.02 * (1 / 50),\n",
    "    T1_2: float = 0.25,\n",
    "    Fs: float = 30.0,\n",
    "    snr_grid: List[int] = list(range(0, 51, 10)),\n",
    ") -> Dict[str, List[List[float]]]:\n",
    "    \"\"\"\n",
    "    Monte-Carlo benchmark for 2-channel “unshuffling” with robust regression.\n",
    "\n",
    "    Pipeline per trial\n",
    "    ------------------\n",
    "    1) Spike locations:\n",
    "       - Build a jittered, minimum-separation grid on [0,1) with spacing `mindist`.\n",
    "       - Draw k=k1+k2 locations without replacement and jitter each within ±1% of `mindist`.\n",
    "       - Split locations into two disjoint sets (channel 1 vs 2).\n",
    "\n",
    "    2) Amplitudes:\n",
    "       - Draw i.i.d. amplitudes U[0.5, 1.0] and split by channel.\n",
    "\n",
    "    3) Simulation:\n",
    "       - For each channel c∈{1,2}, simulate time series of length N using\n",
    "         `simulate_noisy_signal` with SNR = `SNR_dB` (in dB) and model `mode`.\n",
    "       - For `mode=\"exp\"`, the kernel is 1/(α + jω); α is set from the half-life T1/2:\n",
    "             α = ln(2) * N / (T1_2 * Fs)\n",
    "\n",
    "    4) Shuffle mask:\n",
    "       - Initialize q_true ∈ {0,1}^N with exactly `flips` ones at random positions (1…N−1).\n",
    "       - Observed channels are swapped according to q_true:\n",
    "             y1_obs = q_true*y1 + (1−q_true)*y2\n",
    "             y2_obs = q_true*y2 + (1−q_true)*y1\n",
    "         The permutation-invariant sum x_sum = y1_obs + y2_obs is preserved.\n",
    "\n",
    "    5) Location estimation (sum signal):\n",
    "       - Denoise + Prony on x_sum to estimate K=k spike locations:\n",
    "             Xk_sum, t_est_sum = denoise_and_prony(...)\n",
    "       - Build time-domain design Ẑ_sum (N×K) via `reconstruction_params`.\n",
    "\n",
    "    6) Unshuffling via robust regression:\n",
    "       - Run `MM_shuffled(y1_obs, y2_obs, Ẑ_sum, ...)` to obtain β₁, β₂ and q̂.\n",
    "\n",
    "    7) Metrics:\n",
    "       - Normalized MSE (nMSE) per trial is defined assignment-invariantly as\n",
    "             nMSE = min{ (1/2)[ MSE(clean1, Ẑβ₁)/pow(clean1)\n",
    "                               + MSE(clean2, Ẑβ₂)/pow(clean2) ],\n",
    "                          (1/2)[ MSE(clean2, Ẑβ₁)/pow(clean2)\n",
    "                               + MSE(clean1, Ẑβ₂)/pow(clean1) ] }\n",
    "         where MSE(a,b) = mean((a−b)²) and pow(clean) = mean(clean²).\n",
    "       - Weighted accuracy for the shuffle mask uses sample weights\n",
    "             w = |clean1 − clean2|\n",
    "         and reports max( Acc(q_true, q̂; w), Acc(1−q_true, q̂; w) )\n",
    "         to account for the label symmetry.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    k1, k2 : int\n",
    "        Number of spikes in channel 1 and 2, respectively.\n",
    "    N : int\n",
    "        Number of time samples per signal.\n",
    "    flips : int\n",
    "        Number of positions with q_true=1 (swap) in the mask.\n",
    "    n_trials : int\n",
    "        Monte-Carlo repetitions per SNR value.\n",
    "    mode : {\"spike\",\"exp\"}\n",
    "        Observation model passed to `simulate_noisy_signal` and `denoise_and_prony`.\n",
    "    seed : int\n",
    "        Seed for NumPy’s Generator.\n",
    "    mindist : float\n",
    "        Minimum separation (in “time” units on [0,1)) between candidate grid points.\n",
    "    T1_2 : float\n",
    "        Half-life in seconds (used only if mode=\"exp\").\n",
    "    Fs : float\n",
    "        Sampling frequency in Hz (used only if mode=\"exp\").\n",
    "    snr_grid : list of int\n",
    "        SNR values (in dB) to sweep.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        {\n",
    "          \"Accuracies\": list over SNR of lists over trials of weighted accuracies,\n",
    "          \"MSEs_sum\" : list over SNR of lists over trials of assignment-invariant nMSE,\n",
    "          \"snr_grid\" : the input SNR grid\n",
    "        }\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - The design matrix Ẑ_sum contains only location information; amplitudes are\n",
    "      learned via regression inside `MM_shuffled`.\n",
    "    - Ensure that external dependencies are imported:\n",
    "        * `simulate_noisy_signal`, `denoise_and_prony`, `reconstruction_params`\n",
    "        * `MM_shuffled`\n",
    "        * `accuracy_score` (scikit-learn) and `trange` (tqdm)\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    k = k1 + k2\n",
    "    alpha = np.log(2) * N / (T1_2 * Fs)\n",
    "    print(alpha)\n",
    "    Accuracies: List[List[float]] = []\n",
    "    MSEs_sum: List[List[float]] = []\n",
    "\n",
    "    for SNR_dB in snr_grid:\n",
    "        Accuracy_tmp: List[float] = []\n",
    "        MSEs_sum_tmp: List[float] = []\n",
    "\n",
    "        for _ in trange(n_trials):\n",
    "            # jittered grid of all spike times, then split into channels\n",
    "            all_times = np.sort(\n",
    "                rng.choice(np.arange(0.5 * mindist, 1, mindist), size=k, replace=False)\n",
    "                + rng.uniform(-0.01 * mindist, 0.01 * mindist, k)\n",
    "            )\n",
    "            idx = np.arange(k, dtype=int)\n",
    "            p1_idx = np.sort(rng.choice(idx, k1, replace=False))\n",
    "            p2_idx = np.sort(np.setdiff1d(idx, p1_idx))\n",
    "\n",
    "            spike_times1 = all_times[p1_idx].tolist()\n",
    "            spike_times2 = all_times[p2_idx].tolist()\n",
    "\n",
    "            # amplitudes\n",
    "            all_amps = rng.uniform(0.5, 1.0, k)\n",
    "            amplitudes_1 = all_amps[p1_idx].tolist()\n",
    "            amplitudes_2 = all_amps[p2_idx].tolist()\n",
    "\n",
    "            # simulate each channel\n",
    "            clean1, y1_noise, _, _, _, _, _ = simulate_noisy_signal(\n",
    "                N=N,\n",
    "                spike_number=k1,\n",
    "                alpha=alpha,\n",
    "                SNR_dB=SNR_dB,\n",
    "                mode=mode,\n",
    "                spike_times=spike_times1,\n",
    "                amplitudes=amplitudes_1,\n",
    "            )\n",
    "            clean2, y2_noise, _, _, _, _, _ = simulate_noisy_signal(\n",
    "                N=N,\n",
    "                spike_number=k2,\n",
    "                alpha=alpha,\n",
    "                SNR_dB=SNR_dB,\n",
    "                mode=mode,\n",
    "                spike_times=spike_times2,\n",
    "                amplitudes=amplitudes_2,\n",
    "            )\n",
    "\n",
    "            # shuffle mask and observations\n",
    "            q_true = np.zeros(N, float)\n",
    "            flip_positions = rng.choice(np.arange(1, N, dtype=int), flips, replace=False)\n",
    "            q_true[np.sort(flip_positions)] = 1.0\n",
    "\n",
    "            y1_obs = q_true * y1_noise + (1.0 - q_true) * y2_noise\n",
    "            y2_obs = q_true * y2_noise + (1.0 - q_true) * y1_noise\n",
    "            x_sum = y1_obs + y2_obs\n",
    "\n",
    "            # denoise + Prony on the sum (perm-invariant) to get locations\n",
    "            Xk_sum, t_est_sum = denoise_and_prony(\n",
    "                signal=x_sum, alpha=alpha, K=k, L=(N - 1) // 2, mode=mode\n",
    "            )\n",
    "\n",
    "            # build design\n",
    "            Z_hat_sum = reconstruction_params(\n",
    "                Xk=Xk_sum, t_est=t_est_sum, N=N, alpha=alpha, mode=mode\n",
    "            )\n",
    "\n",
    "            # robust MM-based estimation for 2-channel unshuffling\n",
    "            b1, b2, _, _, q_hat, losses = MM_shuffled(\n",
    "                y1_obs, y2_obs, Z_hat_sum, outeriter=5, bdp=0.5\n",
    "            )\n",
    "\n",
    "            # assignment-invariant normalized MSE\n",
    "            mse11 = 0.5 * (\n",
    "                np.mean((clean1 - Z_hat_sum @ b1) ** 2) / np.mean(clean1 ** 2)\n",
    "                + np.mean((clean2 - Z_hat_sum @ b2) ** 2) / np.mean(clean2 ** 2)\n",
    "            )\n",
    "            mse21 = 0.5 * (\n",
    "                np.mean((clean2 - Z_hat_sum @ b1) ** 2) / np.mean(clean2 ** 2)\n",
    "                + np.mean((clean1 - Z_hat_sum @ b2) ** 2) / np.mean(clean1 ** 2)\n",
    "            )\n",
    "            mse_sum = min(mse11, mse21)\n",
    "            MSEs_sum_tmp.append(mse_sum)\n",
    "\n",
    "            # weighted accuracy for q (label-swap invariant)\n",
    "            w = np.abs(clean1 - clean2)\n",
    "            acc1 = accuracy_score(q_true, q_hat, sample_weight=w)\n",
    "            acc2 = accuracy_score(1.0 - q_true, q_hat, sample_weight=w)\n",
    "            Accuracy_tmp.append(max(acc1, acc2))\n",
    "\n",
    "        Accuracies.append(Accuracy_tmp)\n",
    "        MSEs_sum.append(MSEs_sum_tmp)\n",
    "        print(\n",
    "            f\"SNR={SNR_dB:2d} dB | Acc={np.mean(Accuracy_tmp):.3f} | nMSE={np.median(MSEs_sum_tmp):.3e}\"\n",
    "        )\n",
    "\n",
    "    return {\"Accuracies\": Accuracies, \"MSEs_sum\": MSEs_sum, \"snr_grid\": snr_grid}\n",
    "\n",
    "\n",
    "# example call:\n",
    "results = run_mc(k1=2, k2=2, N=121, flips=40, n_trials=100, mode=\"spike\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_mc_results(results):\n",
    "    \"\"\"\n",
    "    Plot Monte-Carlo performance curves (accuracy and normalized MSE) vs. SNR.\n",
    "\n",
    "    Expects a results dictionary as returned by `run_mc`, containing:\n",
    "        {\n",
    "          \"Accuracies\": list over SNR of per-trial weighted accuracies,\n",
    "          \"MSEs_sum\"  : list over SNR of per-trial normalized MSE values,\n",
    "          \"snr_grid\"  : list of SNR values in dB\n",
    "        }\n",
    "\n",
    "    The function computes median and interquartile ranges (IQR: 25th–75th percentile)\n",
    "    across trials for both accuracy and nMSE, then plots:\n",
    "        (1) Weighted accuracy vs. SNR (linear y-axis)\n",
    "        (2) Normalized MSE vs. SNR (log-scale y-axis)\n",
    "\n",
    "    Each subplot shows:\n",
    "      • Median curve with markers\n",
    "      • Shaded IQR region\n",
    "      • Optional scatter of individual trial results\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    results : dict\n",
    "        Dictionary returned by `run_mc` with keys:\n",
    "            \"snr_grid\"  → list[int] or array-like of SNR values in dB\n",
    "            \"Accuracies\" → list[list[float]], per-SNR trial accuracies\n",
    "            \"MSEs_sum\"   → list[list[float]], per-SNR trial normalized MSEs\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "        Displays a matplotlib figure with two subplots:\n",
    "            Left  – weighted accuracy vs SNR\n",
    "            Right – normalized MSE (log-scale) vs SNR\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - Uses median and IQR (25–75%) as robust statistics across trials.\n",
    "    - All scatter points are semi-transparent to show distribution spread.\n",
    "    - The nMSE axis is plotted on a log scale for dynamic range visualization.\n",
    "    - Style: \"seaborn-v0_8-whitegrid\" for consistent appearance.\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "    >>> results = run_mc(k1=2, k2=2, N=121, flips=40, n_trials=100, mode=\"spike\")\n",
    "    >>> plot_mc_results(results)\n",
    "    \"\"\"\n",
    "    snr_vals = np.array(results[\"snr_grid\"])\n",
    "    Accuracies = results[\"Accuracies\"]\n",
    "    MSEs_sum   = results[\"MSEs_sum\"]\n",
    "\n",
    "    # --- aggregate statistics ---\n",
    "    acc_meds = [np.median(a) for a in Accuracies]\n",
    "    acc_q25  = [np.percentile(a, 25) for a in Accuracies]\n",
    "    acc_q75  = [np.percentile(a, 75) for a in Accuracies]\n",
    "\n",
    "    mse_meds = [np.median(m) for m in MSEs_sum]\n",
    "    mse_q25  = [np.percentile(m, 25) for m in MSEs_sum]\n",
    "    mse_q75  = [np.percentile(m, 75) for m in MSEs_sum]\n",
    "\n",
    "    plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "    # ---- (1) Weighted accuracy plot ----\n",
    "    ax[0].plot(snr_vals, acc_meds, 'o-', color='tab:blue', lw=2, label='Median')\n",
    "    ax[0].fill_between(snr_vals, acc_q25, acc_q75, color='tab:blue', alpha=0.2, label='IQR')\n",
    "    for s, arr in zip(snr_vals, Accuracies):\n",
    "        ax[0].scatter([s]*len(arr), arr, color='tab:blue', alpha=0.25, s=10)\n",
    "    ax[0].set_xlabel(\"SNR [dB]\", fontsize=12)\n",
    "    ax[0].set_ylabel(\"Weighted accuracy\", fontsize=12)\n",
    "    ax[0].set_ylim(0, 1.05)\n",
    "    ax[0].set_title(\"Unshuffling accuracy vs SNR\", fontsize=13)\n",
    "    ax[0].grid(True, ls=':')\n",
    "    ax[0].legend(frameon=False)\n",
    "\n",
    "    # ---- (2) Normalized MSE plot ----\n",
    "    ax[1].plot(snr_vals, mse_meds, 's-', color='tab:red', lw=2, label='Median')\n",
    "    ax[1].fill_between(snr_vals, mse_q25, mse_q75, color='tab:red', alpha=0.2, label='IQR')\n",
    "    for s, arr in zip(snr_vals, MSEs_sum):\n",
    "        ax[1].scatter([s]*len(arr), arr, color='tab:red', alpha=0.25, s=10)\n",
    "    ax[1].set_xlabel(\"SNR [dB]\", fontsize=12)\n",
    "    ax[1].set_ylabel(\"Normalized MSE\", fontsize=12)\n",
    "    ax[1].set_yscale(\"log\")\n",
    "    ax[1].set_title(\"Reconstruction nMSE vs SNR\", fontsize=13)\n",
    "    ax[1].grid(True, which=\"both\", ls=':')\n",
    "    ax[1].legend(frameon=False)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m plot_mc_results(\u001b[43mresults\u001b[49m)\n",
      "\u001b[31mNameError\u001b[39m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "plot_mc_results(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
